[toc]

# 项目开发报告

## 1.1 项目目的

(1) 掌握SVM、Logistics、Neural Network等底层算法

(2) 加强使用python、shell等语言的熟练程度

(3) 加强自身的工程开发与调试能力

(4) 掌握通过Python分析数据、绘制图表的能力

(5) 分析预测疫情期间网民们的情绪走势



## 1.2 问题分析

### 1.2.1 题目背景

2019 新型冠状病毒(COVID-19)感染的肺炎疫情发生对人们生活生产的方方面面产生了重要影响，并引发国内舆论的广泛关注，众多网民参与疫情相关话 题的讨论。为了帮助政府掌握真实社会舆论情况，科学高效地做好防控宣传和舆 情引导工作，本题目针对疫情相关话题开展网民情绪识别的任务。

### 1.2.2 数据集

据集依据与“新冠肺炎”相关的 230 个主题关键词进行数据采集，抓取了 2020 年 1 月 1 日—2020 年 2 月 20 日期间微博数据，并对其进行人工标注，标注 分为三类，分别为:1(积极)，0(中性)和-1(消极)。

训练数据以 csv 格式存储在 train.csv 文件中，其中包含 45000 条微博数 据，具体格式如下:

| 微博中文内容                 | 情感倾向                   |
| ---------------------------- | -------------------------- |
| 1.微博中文内容，格式为字符串 | 2.情感倾向，取值为{1,0,-1} |







### 1.2.3 任务描述

根据 train.csv 文件中的微博数据，设计算法对 test.csv 文件中的 4500 条

微博内容进行情绪识别，判断微博内容是积极的(1)、消极的(-1)还是中性的 (0)。

将结果存储在 csv 文件中，编码采用 UTF-8 编码，格式如下: 

| 微博中文内容   | 情感倾向 |
| -------------- | -------- |
| 新冠肺炎...... | 1        |
|                |          |

### 1.2.4 思路分析

通过NLP来进行情感分析在市面上已经有了非常成熟的体系。SVM、Logistics、Neural Network等算法都是非常好的解决方案，而scikit-learn和SnowNLP都是比较成熟的情感分析框架了。以下是在sklearn和SnowNLP两者进行选择的心路历程:

![image-20200727095320081](/Users/alexfan/Library/Application Support/typora-user-images/image-20200727095320081.png)

所以最后选择了SnowNLP来作为主要的设计方法，**其他算法仅做基础实现而不用过度优化。**

而本次项目设计中比较新颖的一点是采用了 -1 / 0 / 1 三分类来进行情感划分，市面上许多算法也都是直接根据Pos/Neg来进行划分的。而SnowNLP可以不仅可以直接对一句话的极性进行打分（0～1），还可以通过内置函数来训练自己的训练集。

![image-20200727094717344](/Users/alexfan/Library/Application Support/typora-user-images/image-20200727094717344.png)

因为给出的是一个浮点数分数而不是具体分类，所以我们需要自己额外训练一个映射模型来进行归一化处理。将浮点数均匀的映射在-1 / 0 / 1 三分类上。

![image-20200727092813176](/Users/alexfan/Library/Application Support/typora-user-images/image-20200727092813176.png)

所以对于SnowNLP方法来说，主要的工作量集中于以下几点：

1. 分割训练集中的-1 / 0 / 1三类文本并保存至Pos.txt / Neu.txt / Neg.txt三个文件中
2. 使用停用词以及正则匹配去除噪声（微博上的用户评论前的各种title会非常影响结果）
3. 训练自己的训练集并保存至文件「sentiment.marshal.3」中
4. 对自己的测试集进行测试，得出归一化之前的句子分数
5. 训练映射模型，将分数均匀映射至-1 / 0 / 1三个分类上
6. 通过强弱校验来分别对结果正确率进行判断。

> 这里没采用混淆矩阵分析的原因是因为这里采用的是三分类而非二分类。

此外还选择了SVM、Logistics、Word2Vec+LSTM三分类来分别训练模型来观察是否能达到比较好的效果。

## 1.3 基于SnowNLP

根据1.2.4中的思路分析，现在我们对此进行扩展详细说明。

<img src="/Users/alexfan/Library/Application Support/typora-user-images/image-20200727165238446.png" alt="image-20200727165238446" style="zoom:67%;" />



> SnowNLP是一个python写的类库，可以方便的处理中文文本内容，是受到了TextBlob的启发而写的，由于现在大部分的自然语言处理库基本都是针对英文的，于是写了一个方便处理中文的类库，并且和TextBlob不同的是，这里没有用NLTK，所有的算法都是自己实现的，并且自带了一些训练好的字典。注意本程序都是处理的unicode编码，所以使用时请自行decode成unicode。

以上是官方对snownlp的描述，简单地说，snownlp是一个中文的自然语言处理的Python库，支持的中文自然语言操作包括：

- 中文分词
- 词性标注
- 情感分析
- 文本分类
- 转换成拼音
- 繁体转简体
- 提取文本关键词
- 提取文本摘要
- tf，idf
- Tokenization
- 文本相似

### 1.3.1 训练测试集分割

训练集的分割方法保存在工程中的covid19/splitNegPos.py中，如需查看源码可自行取用。

```python
 def startSplit(self, posnum, negnum, midnum, testnum):
        file = open("train&test/pos.txt", 'w')
        for comment in self.pos[0:posnum]:
            comment = self.cleanComment(comment)
            if comment != '':
                file.write(comment)
                file.write('\n')
        file.close()

        file = open("train&test/neg.txt", 'w')
        ............

        file = open("train&test/mid.txt", 'w')
        ............

        data = pd.read_csv('train&test/test.csv', encoding='utf-8')
        with open('train&test/test.txt', 'w', encoding='utf-8') as f:
            for line in data.values[0:testnum]:
                testline = self.cleanComment(str(line[0]))
                f.write((testline + '\n'))
```

该部分的实现主要依赖于pandas下的read_csv()函数来进行拆分合并文件。我们要做的工作主要是将文件-1 / 0 / 1三个分类分别划分到pos.txt / neu.txt / neg.txt三个文件中。并且将test.csv中的正确结果导入进txt中。

### 1.3.2 数据清洗降噪

在微博中，许多文本都包含许多奇怪的title和转发链接，所以我们需要通过正则表达式以及停用词消除一些对情感没有太大影响的词汇。

<img src="/Users/alexfan/Library/Application Support/typora-user-images/image-20200727235301738.png" alt="image-20200727235301738" style="zoom:60%;" />

```python
def cleanComment(self, comment):
 		comment = re.sub('#.*#', '', comment)
 		comment = re.sub('//@.*:', '', comment)
 		comment = re.sub('//@.*：', '', comment)
 		comment = re.sub('//.*:', '', comment)
 		comment = re.sub('//.*：', '', comment)
 		comment = re.sub('【.*】', '', comment)
 		comment = re.sub('《.*》', '', comment)
 		comment = re.sub('//.*//', '', comment)
 		comment = re.sub('@.*：', '', comment)
 		comment = re.sub('@.*:', '', comment)
 		comment = re.sub('『.*』', '', comment)
 		comment = re.sub(r'\d', '', comment)
 		return comment
```

以上是调用re中正则表达式匹配库中的sub()方法，来消除一些奇怪的title。比如：`//@整点电影:` `//@【整点电影】:`

然后在清洗完了之后，再进行去除停用词。GitHub上有许多停用词库，本项目选用的是哈工大的停用词库和百度的停用词库。以下是去停用词的cut2wd()方法。

<img src="/Users/alexfan/Library/Application Support/typora-user-images/image-20200727170808869.png" alt="image-20200727170808869" style="zoom:50%;" />



### 1.3.3 训练集定制

经过去停之后，我们可以去定制自己专属的训练集。其核心的训练方法还是基于贝叶斯模型的。

```python
def train(self, data):
    # data 中既包含正样本，也包含负样本
    for d in data: # data中是list
        # d[0]:分词的结果，list
        # d[1]:正/负样本的标记
        c = d[1]
        if c not in self.d:
            self.d[c] = AddOneProb() # 类的初始化
        for word in d[0]: # 分词结果中的每一个词
            self.d[c].add(word, 1)
    # 返回的是正类和负类之和
    self.total = sum(map(lambda x: self.d[x].getsum(), self.d.keys())) # 取得所有的d中的sum之和
```

在实际的项目中，需要根据实际的数据重新训练情感分析的模型，大致分为如下的几个步骤：

- 准备正负样本，并分别保存，如正样本保存到`pos.txt`，负样本保存到`neg.txt`；
- 利用snownlp训练新的模型
- 保存好新的模型

但是我们需要在`/Users/***/anaconda3/lib/python3.7/site-packages/snownlp/sentiment/__init__.py`下对于SnowNLP的sentiment.marshal路径进行修改。不再使用模型自带的sentiment.marshal。

<img src="/Users/alexfan/Library/Application Support/typora-user-images/image-20200727172801804.png" alt="image-20200727172801804" style="zoom:75%;" />

情感分类的基本模型是贝叶斯模型Bayes，对于贝叶斯模型，可以参见文章简单易学的机器学习算法——朴素贝叶斯。对于有两个类别`c1`和`c2`的分类问题来说，其特征为w1,⋯,wn，特征之间是相互独立的，属于类别`c1`的贝叶斯模型的基本过程为：

<img src="/Users/alexfan/Library/Application Support/typora-user-images/image-20200727173412783.png" alt="image-20200727173412783" style="zoom:50%;" />

其中:<img src="/Users/alexfan/Library/Application Support/typora-user-images/image-20200727173443629.png" alt="image-20200727173443629" style="zoom:50%;" />

训练之后，保存sentiment.marshal.3文件在我们自定义的data_path中。

### 1.3.4 测试集评分

在训练完成之后，可以通过内置的snownlp()函数来进行评分。但是得到的都是0～1的浮点数的结果

![image-20200727173923914](/Users/alexfan/Library/Application Support/typora-user-images/image-20200727173923914.png)

- 返回值为正面情绪的概率

- 越接近1表示正面情绪

- 越接近0表示负面情绪

但是我们需要的结果是三分类的-1 / 0 / 1 的结果，所以在测试结束后，把所有的浮点数结果存放在result数组里，等待下面的映射模型来进行转换。

### 1.3.5 映射模型

为了解决三分类的映射关系问题，我们需要将浮点结果映射到-1 / 0 / 1上，最好的办法就是先查看每种结果在三条线上的分布图，再按照0.02的步长来选择left和right的界线（通过chooseLeftAndRight( )）。对每种情况划分后来统计结果。

<img src="/Users/alexfan/Library/Application Support/typora-user-images/image-20200727175457048.png" alt="image-20200727175457048" style="zoom:50%;" />

以上chooseLeftAndRight方法则是按照指定的num步长来划分归一化处理。


```python
def chooseLeftAndRight(pos, neu, neg, num):
    left = []
    right = []
    sum = []
    for l in range(num):
        for r in range(l, num):
            correct = 0
            for n in range(0, l):
                correct += neg[n]
            for n in range(l, r):
                correct += neu[n]
            for p in range(r, num+1):
                correct += pos[p]
            print(correct)
            sum.append(correct)
            left.append(l*(1/num))
            right.append(r*(1/num))
    return left, right, sum
```

部分结果如下图：

<img src="/Users/alexfan/Library/Application Support/typora-user-images/image-20200727180716805.png" alt="image-20200727180716805" style="zoom:50%;" />



## 1.4 SVM 方法

因为`1.3`中已经讲过了关于数据预处理，并且校验方法可以复用，所以

## 1.5 基于LSTM三分类方法



## 1.6 基于Logistic回归模型

## 1.7 结果分析

### 1.7.1 SnowNLP结果分析

在1.3中我们得到的最优左界: 0.54 右界: 0.98，测试结果如下

校验函数如下：

```python
def checkResult(result, realResult):
    correct = 0
    for i in range(len(result)):
        if result[i] == realResult[i]:
            correct += 1
    print("\n强校验正确率=====================================>")
    print(correct/len(result))
    print("正确结果数量：{}".format(correct))
    print("全部结果数量：{}".format(len(realResult)))
    return correct, len(result)


def checkResultNoNeu(result, realResult):
    correct = 0
    sum = 0
    for i in range(len(result)):
        if realResult[i] != 0:
            sum += 1
        if result[i] == realResult[i]:
            correct += 1
    print("\n无中性校验正确率=====================================>")
    print(correct/sum)
    print("正确结果数量：{}".format(correct))
    print("全部结果数量：{}".format(sum))
    return correct, sum


def checkResultCombNeuAndPos(result, realResult):
    correct = 0
    for i in range(len(result)):
        if realResult[i] == -1:
            if result[i] == -1:
                correct += 1
        else:
            if result[i] == 1 or result[i] == 0:
                correct += 1
    print("\n弱校验正确率=====================================>")
    print(correct/len(result))
    print("正确结果数量：{}".format(correct))
    print("全部结果数量：{}".format(len(realResult)))
    return correct, len(realResult)
```



![image-20200727094116474](/Users/alexfan/Library/Application Support/typora-user-images/image-20200727094116474.png)

分析可以得出其预测结果正确率大致为0.55，如果只校验pos和neg的结果的话，正确率却会大幅度上升，分析可以发现是因为在SnowNLP模型下对于pos / neu语句的评分相差无几，所以才会导致强校验结果下正确率趋近0.55而弱校验的正确率很高。



### 1.7.2 SVM结果分析



### 1.7.3 基于LSTM三分类结果分析

## 1.8 思考和总结



SnowNLP是一个python写的类库，可以方便的处理中文文本内容，是受到了TextBlob的启发而写的，由于现在大部分的自然语言处理库基本都是针对英文的，于是写了一个方便处理中文的类库，并且和TextBlob不同的是，这里没有用NLTK，所有的算法都是自己实现的，并且自带了一些训练好的字典。

而机器学习来分析文本的情感其实很多时候是个伪命题，在业界的应用价值其实没有想象中那么高。而且一句话的情感程度在不同人眼里是完全不一样的，并且微博上许多人喜欢阴阳怪气的去发表一些观点。而且打标签的时候，会受到一句话的各种title的影响。而预测的结果也会出现千奇百怪的偏差。

不过这门课，这个选题的核心是为了帮助我们去理解分类器是如何工作的。通过贝叶斯来进行特征的分类与聚合，将视线从纯粹的代码逻辑拉回到数学逻辑上，这是一件非常精妙的事情。这也让机器学习这门课变的十分有意义而且趣味性更高了。

